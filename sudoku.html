<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Sudoku - Daniel J. Kraft</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
    
<script type="text/javascript"
        src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>		
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="index.html" class="logo"><strong>Daniel Kraft's</strong> Portfolio</a>
									<ul class="icons">
										<li><a href="https://linkedin.com/in/daniel-j-kraft" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
										<li><a href="https://github.com/Daniel-J-Kraft" class="icon brands fa-github"><span class="label">Github</span></a></li>
										<li><a href="puzzle.html" class="icon brands fa-soundcloud"><span class="label">Soundcloud</span></a>
									</ul>
								</header>

							<!-- Content -->
								<section>
									<header class="main">
										<h1>Solving Sudoku</h1>
										
									</header>

									<span class="image main"><img src="images/pic11.jpg" alt="" /></span>

									<p>In this project, I show how one can formulate a Sudoku puzzle as a convex minimization problem. I discuss the strengths and weaknesses of this approach and compare the results to some brute force methods commonly used to solve Sudoku puzzles. While there are faster and more consistent ways to solve Sudoku, this was an interesting dive into convex optimization and using L1 Norms to produce sparse solutions to linear systems.</p>
									<div>
										<ul class="actions_test2">
											<li><a href="https://github.com/Daniel-J-Kraft/Sudoku-Solvers" class="button">Github</a></li>
										</ul>
									</div>
								</section>

								<section id="banner">
									

									<div class="content_centered">
										<h2>Formulating the Problem</h2>
										<p>In order to solve a puzzle as a convex problem, we must formulate the problem as a set of linear equations. To do this we must first be able to represent the state of a puzzle as a single binary vector. To do this we turn the 9x9 sudoku grid to an 81 dimensional vector. We then further extend each entry by 9, getting a resulting in a 729 dimensional vector. Every 9 entries in this vector represent a single Sudoku square. To be well formed there should only be a single 1 entry in each of these blocks, a ones in the first place corresponds to a 1, a one in the second place corresponds to a 2 etc. For instance, the sudoku puzzle to the right is represented as follows. </p>
									</div>
									<span class="image object">
										<img src="images/sudoku/vect2.png" alt="" />
									</span>
								</section>

								<section id="banner">
									<span class="image object">
										<img src="images/sudoku/constraints.png" alt="" />
									</span>
									<div class="content_centered">
										<p>We then construct the constraint matrix. We choose the constraint matrix to be such that a valid Sudoku solution will satisfy the equation Ax = 1. It is shown to the left how to accomplish this for the first column, row, or 3x3 block.  </p>
									</div>
									
								</section>

								<section id="banner">
									<div class="content_centered">
										<p>By contiuing to create these rules for all rows, columns, and 3x3 principle blocks we recieve the constraint matrix shown to the right. The white pixels correspond to ones of the matrix and the rest are zeros. Note that any valid form of a matrix solution, encoded into our binary vector form, will satisfy the equation Ax=1. Howver, there are many 'solutions' to the linear system that are not well formed sudoku puzzles. Therefore, it is not sufficient to find solutions to our linear systems to solve an individual sudoku puzzle.</p>
									</div>
									<span class="image object">
										<img src="images/sudoku/RankDef.png" alt="" />
									</span>									
								</section>

								<section id="banner">
									<span class="image object">
										<img src="images/sudoku/FullRankHint.png" alt="" />
									</span>
									<div class="content_centered">
										<p>We can take our original constraint matrix and use a QR decomposition to get the linear independent rows of the matrix to produce a full rank matrix. This will not change the solutions of the linear system and will make computations more efficient. We can then encode the specifics of an individual puzzle by adding a row with a single 1's entry in the corresponding spot to each individual initial number. If there are 15 initial points then we add 15 additional rows. The resulting matrix is shown to the left. </p>
									</div>
								</section>

								<section id="banner">
									<div class="content">
										<h2>L1-Norm Minimization</h2>
										<p>It is clear that a valid Sudoku solution will satisfy the set of linear equations. However, the converse is certainly not true. It is here that we use the concept of sparsity to help converge to a correct solution. Assume we have a Sudoku puzzle with a unique solution X_s. We show the solution to min ||X||_0 = X_s. We know any Sudoku solution X_s will satisfy the condition ||X_s||_0 = N^2. Now assume there exists a solution X_S^* \neq X_s and X_s^* < N^2. Then not every cell in the Sudoku puzzle will be filled. Then for all feasible X, ||X||_0 \geq N^2.</p>
									</div>									
								</section>

								<section id="banner">
									<div class="content_centered">
										<p>We run our experiments by generating random initializations of Sudoku boards with a specified number of 'hints'. For each number of initial hints we run 100 experiments, we record the average of all successful attempts. We can see that  using this method only reliably solves the problem when there are more than 40 initial hints. This is... not great. The average Sudoku puzzle has 21 initial hints so this is not adequate. </p>
									</div>
									<span class="image object">
										<img src="images/sudoku/OrigSuc.png" alt="" />
									</span>
									
								</section>


								<section id="banner">
									<span class="image object">
										<img src="images/sudoku/OrigRate.png" alt="" />
									</span>
									<div class="content_centered">
										<p>We can now look at the time it takes for each algorithm in question to succesfully solve a puzzle. We can see that using the linear independent versions of the constraint matrix runs apprecialbly faster, and python's linprog solver is faster than CVXOPT's solvers.</p>
									</div>
									
								</section>

								<section id="banner">
									<div class="content_centered">
										<p>We now introduce the backtracking algorithm, which is a brute force method of solving a Sudoku puzzle. This is a recursive program that works in the following way. It looks at the first available spot and puts a 1 in it. It then goes to the next and puts a 2, if there is a contradiction it ups the number by one. If it runs through all possible iterations in an individual square and there are no valid numbers it goes back to the previous entry and increases it by one. It continues in this way until the solution is found. The results of the backtracking algorithm is shown below.</p>
									</div>
									<span class="image object">
										<img src="images/sudoku/Backtracking.gif" alt="" />
									</span>
									
								</section>


								<section id="banner">
									<span class="image object">
										<img src="images/sudoku/BackSuc.png" alt="" />
									</span>
									<div class="content_centered">
										<p>As we can see the backtracking algorithm solves puzzles with 100% accuracy. However, the downside of backtracking is evident when looking at the run time of the algorithm.</p>
									</div>
								</section>


								<section id="banner">
									<div class="content_centered">
										<p>We see that the algorithm takes a comparatively long time to solve any puzzle with under 30 hints. However, when there are any more than 35 initial hints the backtracking algorithm solves the puzzle faster than any of the linear program solvers. We see that backtracking always outperforms our $\ell_1$ minization algorithms. When there are few hints, backtracking takes a long time, but it is successful where the $\ell_1$ minimization algorithms are not. When there are many hints, both algorithms solve the puzzle, but backtracking is faster. If this were the end of our analysis, there would be no reason to use $\ell_1$ minimization over backtracking.</p>
									</div>
									<span class="image object">
										<img src="images/sudoku/BackTime.png" alt="" />
									</span>
									
								</section>

								<section id="banner">
									<div class="content">
										<h2>Weighted L1-Norm Minimization</h2>
										<p>When using the $\ell_1$ heuristic, we hope that the solution generated will be equivalent to the solution of the $\ell_0$ norm.</p>
										$$ \min_x \sum^n_{i=1} \left\lVert x_i \right\rVert _0 \iff  \min_x \sum^n_{i=1} |x_i|$$
										<p>However, there is a problem with the `1 norm heuristic. When there is a large discrepancy of magnitudes within a vector, this equivalency starts to break down. To fix this we attempt to add strictly positive weights to each entry of the sum with the hope that the weighted `1 norm will more closely represent the $\ell_0$ norm.</p>
										<h5>Weighting Choices</h5>
										<p>The most obvious choice of weights is a strict reciprocal of the solution vector, as shown below:</p>
										$$w_i = \begin{cases}1\over x_i & x_i \ne 0\\ \infty & x= 0 \\ \end{cases}$$
										<p>If the true signal x0 is k-sparse, i.e., obeys $\left\lVert x_0 \right\rVert_{\ell_0} \leq k$ then the above choice of weights is guaranteed to find the correct solution, since it is equivalent to the $\ell_0$ norm. However, this requires prior knowledge of the signal x0 itself, which in general we do not know. However, this gives us an intuition on how to proceed and what we should be looking for. Whatever weight we choose should have some inverse proportionality with the individual entries of the recovery vector. The algorithm we use for this project starts with a weighting vector of all ones:</p>
										$$w^{(0)}=1^{(n\times 1)}$$
										<p>We then solve the linear program with this weighting vector:</p>
										$$ x^{(\ell)} = argmin  ||w^Tx||_1 $$
										<p>Notice that the first iteration is simply the `1 minimization technique described earlier. Once this is done, we update the weights according to the following rule:</p>
										$$ w_i^{(1 + \ell)}= {1\over|x^\ell_i|+\epsilon} $$
										<p> Where is to be chosen as a number slightly less than the maximum modulus of our solution vector. In our case, since our solution vector is binary, $\epsilon\in[0.5, 1)$, we for our experiments we choose $\epsilon = 0.5$.  is included to increase the stability of the algorithm and to ensure that a zero-valued component in $x^{(\ell)}$ does not strictly prohibit a nonzero estimate at the next step. The paper claims that the choice of epsilon is fairly robust and we show this to be true later in this paper. The algorithm is terminated when
										$$ \left\lVert x_i - x_{i-1}\right\rVert^2_2 < k $$ Where k is some stopping tolerance. There is also a maximum iterations parameter that will terminate the program if it has not reached the stopping tolerance in a certain amount of iterations.
</p>

</p>
									</div>									
								</section>


								<section id="banner">									
									<div class="content_centered">
									<p>We show the effectiveness of reweighted $\ell_1$ minimization with a compressed sensing example. Say you are given a random $\Phi$ matrix:
									$\Phi = \begin{bmatrix}
										2 & 1 & 1 \\
										1 & 1 & 2
										\end{bmatrix} $ Observe that th sparsest solution to this linear system is given by:
										$ x_0 = \begin{bmatrix}
										0 \\
										1 \\
										0
										\end{bmatrix} $ and when we multiply these two together we get 
										$ y = \Phi x_0 = \begin{bmatrix}
										1 \\
										1
										\end{bmatrix} $ We can visualie this solution to the right in (a).</p>									
									</div>
									<span class="image object">
										<img src="images/sudoku/WeightedPic.png" alt="" />
									</span>
								</section>
								<section id="banner">
									<div class="content">
										<p>However, when we minimize using the $\ell_1$ norm, we get the vector: $ x^* = \begin{bmatrix}
										1\over 3 \\
										0 \\
										1\over 3
										\end{bmatrix} $ which has an $\ell_1$ norm of 2. We see that in this situation the $\ell_1$ norm solution does not correspond the the $\ell_0$ norm solution. This is visualized well in (b). In order to fix this, we use the weighting vector that we introduced earlier: $ x^* = \begin{bmatrix}
										3 \\
										1 \\
										3
										\end{bmatrix} $When we use the $\ell_1$ minimization technique on this weighted sum we get the sparsest vector, as visualized in (c). It is easily checked that as long as we had chosen the weighting vector such that: $w_2 \leq {w_1 + w_3 \over 3}$ Then we would have recovered the sparsest solution to our linear equation.</p>
									</div>
								</section>


								<section id="banner">
									<span class="image object">
										<img src="images/sudoku/FinalSuc.png" alt="" />
									</span>
									<div class="content_centered">
										<p>We can use this iterative algorithm on our Sudoku solvers. We set = 0.5, the stopping tolerance k = 1 × 10−4, and the maximum iterations to 50. With this setup, we find the success rate of our solvers to be. We can see that using the reweighted algorithm produces much better success results. For any amount of initial hints, the reweighted schema solves the puzzle roughly half of the time, and solves with high probability starting around 25 initial hints. If we look at the time average of this algorithm</p>
									</div>
									
								</section>


								<section id="banner">
									<div class="content_centered">
										<p>We see that it takes on average about twice as long as the original $\ell_1$ technique. Since the results are so much more reliable, it is well worth the extra computational time.</p>
									</div>
									<span class="image object">
										<img src="images/sudoku/FinalTime.png" alt="" />
									</span>
								</section>

								<section id="banner">
									<span class="image object">
										<img src="images/sudoku/EasySuc.png" alt="" />
									</span>
									<span class="image object">
										<img src="images/sudoku/EasyTime.png" alt="" />
									</span>
									
								</section>

								<section id="banner">
									<p></p>
									<span class="image object">
										<img src="images/sudoku/HardSuc.png" alt="" />
									</span>
									<span class="image object">
										<img src="images/sudoku/HardTime.png" alt="" />
									</span>
									
								</section>

								

						</div>
					</div>

				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">

							<!-- Search -->
								<section id="search" class="alt">
									<form method="post" action="#">
										<input type="text" name="query" id="query" placeholder="Search" />
									</form>
								</section>

							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									<ul>
									<li><a href="index.html">Homepage</a></li>
									<li><a href="experience.html">Experience</a></li>
										<li><a href="dec_opt.html">Decentralized Optimization</a></li>
										<li>
											<span class="opener">Mathematical Contest in Modeling</span>
											<ul>
												<li><a href="mcm_over.html">MCM Overview</a></li>
												<li><a href="mcm20.html">2020 - Simulating Sandcastles</a></li>
												<li><a href="mcm19.html">2019 - Apex Predater/Prey</a></li>
											</ul>
										</li>
										
										<li><a href="sudoku.html">Sudoku Solver</a></li>
										<li><a href="comm_det.html">Community Detection</a></li>
										<li><a href="targ_det.html">Target Detection and Registration</a></li>
									</ul>
								</nav>

							<!-- Section -->
								<!--<section>
									<header class="major">
										<h2>Ante interdum</h2>
									</header>
									<div class="mini-posts">
										<article>
											<a href="#" class="image"><img src="images/pic07.jpg" alt="" /></a>
											<p>Aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore aliquam.</p>
										</article>
										<article>
											<a href="#" class="image"><img src="images/pic08.jpg" alt="" /></a>
											<p>Aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore aliquam.</p>
										</article>
										<article>
											<a href="#" class="image"><img src="images/pic09.jpg" alt="" /></a>
											<p>Aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore aliquam.</p>
										</article>
									</div>
									<ul class="actions">
										<li><a href="#" class="button">More</a></li>
									</ul>
								</section>-->

							<!-- Section -->
								<section>
									<header class="major">
										<h2>Get in touch</h2>
									</header>
									<p>Feel free to reach out with any work or collaboration opportunities you have.</p>
									<ul class="contact">
										<li class="icon solid fa-envelope"><a href="#">danieljk46@gmail.com</a></li>
										<li class="icon solid fa-phone">(240) 561-2819</li>
									</ul>
								</section>

							<!-- Footer -->
								<footer id="footer">
									<p class="copyright">&copy; Easter Egg Inc. All rights reserved. Find the 'fire' to start.</p>
								</footer>
						</div>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>